{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing in Washington D.C.\n",
    "\n",
    "Statistical Programming - Python | MBD OCT 2018  \n",
    "*IE School of Human Sciences and Technology*  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case study of the Washington D.C Bike Sharing System aims to predict the total number of users on an hourly basis. The dataset is [available on Kaggle](https://www.kaggle.com/marklvl/bike-sharing-dataset/home). It contains usage information of years 2011 and 2012.\n",
    "\n",
    "All the files of this project are saved in a [GitHub repository](https://github.com/ashomah/Bike-Sharing-in-Washington)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses a set of libraries for data manipulation, ploting and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd #Data Manipulation - version 0.23.4\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np #Data Manipulation - version 1.15.4\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt #Plotting - version 3.0.2\n",
    "import matplotlib.ticker as ticker #Plotting - version 3.0.2\n",
    "import seaborn as sns #Plotting - version 0.9.0\n",
    "sns.set(style='white')\n",
    "\n",
    "from sklearn import preprocessing #Preprocessing - version 0.20.1\n",
    "from sklearn.preprocessing import MinMaxScaler #Preprocessing - version 0.20.1\n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax #Preprocessing - version 1.1.0\n",
    "from scipy.special import boxcox1p #Preprocessing - version 1.1.0\n",
    "import statsmodels.api as sm #Outliers detection - version 0.9.0\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Train/Test Split - version 0.20.1\n",
    "from sklearn.model_selection import TimeSeriesSplit,cross_validate #Timeseries CV - version 0.20.1\n",
    "from sklearn import datasets, linear_model #Model - version 0.20.1\n",
    "from sklearn.linear_model import LinearRegression #Model - version 0.20.1\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score #Metrics - version 0.20.1\n",
    "from sklearn.metrics import accuracy_score #Metrics - version 0.20.1\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict # CV - version 0.20.1\n",
    "from sklearn.feature_selection import RFE #Feature Selection - version 0.20.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored in the [GitHub repository](https://github.com/ashomah/Bike-Sharing-in-Washington) consisting in two CSV file: `day.csv` and `hour.csv`. The files are loaded directly from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df = pd.read_csv(\"https://raw.githubusercontent.com/ashomah/Bike-Sharing-in-Washington/master/Bike-Sharing-Dataset/hour.csv\")\n",
    "hours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df = pd.read_csv(\"https://raw.githubusercontent.com/ashomah/Bike-Sharing-in-Washington/master/Bike-Sharing-Dataset/day.csv\")\n",
    "days_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Types and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first stage of this analysis is to describe the dataset, understand the meaning of variable and perform the necessary adjustments to ensure that the data will be proceeded correctly during the Machine Learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data frame\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('hour.csv:', hours_df.shape[0],'rows |', hours_df.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('day.csv:', days_df.shape[0],'rows |', days_df.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe each variable\n",
    "def df_desc(df):\n",
    "    import pandas as pd\n",
    "    desc = pd.DataFrame({'dtype': df.dtypes,\n",
    "                         'NAs': df.isna().sum(),\n",
    "                         'Numerical': (df.dtypes != 'object') & (df.dtypes != 'datetime64[ns]') & (df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() != len(df)),\n",
    "                         'Boolean': df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() == len(df),\n",
    "                         'Categorical': df.dtypes == 'object',\n",
    "                         'Date': df.dtypes == 'datetime64[ns]',\n",
    "                        })\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc(days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc(hours_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset `day.csv` consists in 731 rows and 16 columns. The dataset `hour.csv` consists in 17,379 rows and 17 columns. Both datasets have the same columns, with an additional column for hours in `hour.csv`.\n",
    "\n",
    "Each row provides information for each day or each hour. None of the attributes contains any NA. Four (4) of these attributes contain decimal numbers, nine (9) contain integers, three (3) contain booleans, and one (1) contains date values stored as string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better readability, the columns of both data frames are renamed and data types are adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HOURS DATASET\n",
    "# Renaming columns names to more readable names\n",
    "hours_df.rename(columns={'instant':'id',\n",
    "                        'dteday':'date',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_bikes',\n",
    "                        'hr':'hour',\n",
    "                        'yr':'year',\n",
    "                        'temp':'actual_temp',\n",
    "                        'atemp':'feeling_temp'},\n",
    "                inplace=True)\n",
    "\n",
    "# Date time conversion\n",
    "hours_df.date = pd.to_datetime(hours_df.date, format='%Y-%m-%d')\n",
    "\n",
    "# Categorical variables\n",
    "for column in ['season', 'holiday', 'weekday', 'workingday', 'weather_condition','month', 'year','hour']:\n",
    "    hours_df[column] = hours_df[column].astype('category')\n",
    "    \n",
    "# DAYS DATASET\n",
    "# Renaming columns names to more readable names\n",
    "days_df.rename(columns={'instant':'id',\n",
    "                        'dteday':'date',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_bikes',\n",
    "                        'yr':'year',\n",
    "                        'temp':'actual_temp',\n",
    "                        'atemp':'feeling_temp'},\n",
    "               inplace=True)\n",
    "\n",
    "# Date time conversion\n",
    "days_df.date = pd.to_datetime(days_df.date, format='%Y-%m-%d')\n",
    "\n",
    "# Categorical variables\n",
    "for column in ['season', 'holiday', 'weekday', 'workingday', 'weather_condition','month', 'year']:\n",
    "    days_df[column] = days_df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hours_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists values of categorical variables\n",
    "categories = {'season': hours_df['season'].unique().tolist(),\n",
    "              'year':hours_df['year'].unique().tolist(),\n",
    "              'month':hours_df['month'].unique().tolist(),\n",
    "              'hour':hours_df['hour'].unique().tolist(),\n",
    "              'holiday':hours_df['holiday'].unique().tolist(),\n",
    "              'weekday':hours_df['weekday'].unique().tolist(),\n",
    "              'workingday':hours_df['workingday'].unique().tolist(),\n",
    "              'weather_condition':hours_df['weather_condition'].unique().tolist(),\n",
    "             }\n",
    "for i in sorted(categories.keys()):\n",
    "    print(i+\":\")\n",
    "    print(categories[i])\n",
    "    if i != sorted(categories.keys())[-1] :print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc(hours_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists values of categorical variables\n",
    "categories = {'season': days_df['season'].unique().tolist(),\n",
    "              'year':days_df['year'].unique().tolist(),\n",
    "              'month':days_df['month'].unique().tolist(),\n",
    "              'holiday':days_df['holiday'].unique().tolist(),\n",
    "              'weekday':days_df['weekday'].unique().tolist(),\n",
    "              'workingday':days_df['workingday'].unique().tolist(),\n",
    "              'weather_condition':days_df['weather_condition'].unique().tolist(),\n",
    "             }\n",
    "for i in sorted(categories.keys()):\n",
    "    print(i+\":\")\n",
    "    print(categories[i])\n",
    "    if i != sorted(categories.keys())[-1] :print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc(days_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contain 17 variables with no NAs:\n",
    "\n",
    "- `id`: numerical, integer values.  \n",
    "  *Record index. This variable won't be considered in the study.*\n",
    "  \n",
    "  \n",
    "- `date`: numerical, date values.  \n",
    "  *Date.*\n",
    "\n",
    "\n",
    "- `season`: encoded categorical, integer between 1 and 4.  \n",
    "  *Season: 1=Spring, 2=Summer, 3=Fall, 4=Winter.*\n",
    "\n",
    "\n",
    "- `year`: encoded categorical, integer between 0 and 1.  \n",
    "  *Year: 0=2011, 1=2012.*\n",
    "  \n",
    "  \n",
    "- `month`: encoded categorical, integer between 1 and 12.  \n",
    "  *Month.*\n",
    "  \n",
    "  \n",
    "- `hour`: encoded categorical, integer between 1 and 23.  \n",
    "  *Hour.*\n",
    "  \n",
    "  \n",
    "- `holiday`: encoded categorical, boolean.  \n",
    "  *Flag indicating if the day is a holiday.*\n",
    "\n",
    "\n",
    "- `weekday`: encoded categorical, integer between 0 and 6.  \n",
    "  *Day of the week (0=Sunday, ... 6=Saturday).*\n",
    "\n",
    "\n",
    "- `workingday`: encoded categorical, boolean.  \n",
    "  *Flag indicating if the day is a working day.*\n",
    "  \n",
    "  \n",
    "- `weather_condition`: encoded categorical, integer between 1 and 4.  \n",
    "  *Weather condition (1=Clear, 2=Mist, 3=Light Rain, 4=Heavy Rain).*\n",
    "\n",
    "\n",
    "- `actual_temp`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized temperature in Celsius (min = -16, max = +50).*\n",
    "\n",
    "\n",
    "- `feeling_temp`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized feeling temperature in Celsius (min = -8, max = +39).*\n",
    "\n",
    "\n",
    "- `humidity`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized humidity.*\n",
    "\n",
    "\n",
    "- `windspeed`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized wind speed.*\n",
    "\n",
    "\n",
    "- `casual`: numerical, integer.  \n",
    "  *Count of casual users.*\n",
    "\n",
    "\n",
    "- `registered`: numerical, integer.  \n",
    "  *Count of registered users. This variable won't be considered in the study.*\n",
    "\n",
    "\n",
    "- `total_bikes`: numerical, integer.  \n",
    "  *Count of total rental bikes (casual+registered). This is the __target variable__ of the study, the one to be modelled.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variable id\n",
    "hours_df= hours_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization over the two years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this study is to build a model to predict the value of the variable `total_bikes`, based on the other variables available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes evolution per day\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.date,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the two years dataset, it seems that the utilization of the bike sharing service has increased over the period. The number of bikes rented per day also seems to vary depending on the season, with Spring and Summer months being showing a higher utilization of the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Month - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# g = sns.lineplot(x = hours_df.month,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Month - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.month,\n",
    "#             y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average utilization per month seems to increase between April and October, with a higher variance too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Hour - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.hour,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.xticks([0, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Hour - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.hour,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Hour - Distribution\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.distplot(hours_df.total_bikes,\n",
    "#              bins = 100,\n",
    "#              color = 'steelblue').axes.set(xlim = (min(hours_df.total_bikes),max(hours_df.total_bikes)),\n",
    "#                                            xticks = [0,100,200,300,400,500,600,700,800,900,1000])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization seems really similar over the day, with 2 peaks around 8am and between 5pm and 6pm. The box plot shows potential outliers in the data, which will be removed after the Feature Construction stage. It also highlight an important variance during day time, especially at peak times. The distribution plot shows that utilization is most of the time below 40 bikes simultaneously, and can reach about 1,000 bikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Season - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.season,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "# plt.xticks([1,2,3,4])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Season - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.season,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fall appears to be the high season, with Summer and Winter having similar utilization shapes. Spring appears to be the low season with, however, potential utilization peaks which can reach the same number of bikes than in high season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Holidays - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.holiday,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Normal Day', 'Holiday'])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilization of bikes during holidays seems lower and with less peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Weekday - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.weekday,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "# plt.xticks([0,1,2,3,4,5,6])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Weekday - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.weekday,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average utilization per hour seems higher at the end of the week, but overall, weekends appear to have lower frequentation and weekdays have higher peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Working Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Working Day - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.workingday,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Non Working Day', 'Working Day'])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilization seems higher during working days, with higher peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Weather Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Weather Condition - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.weather_condition,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Clear', 'Mist', 'Light Rain', 'Heavy Rain'])\n",
    "# plt.xticks([1,2,3,4])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Weather Condition - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.weather_condition,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue') \\\n",
    "#    .axes.set_xticklabels(['Clear', 'Mist', 'Light Rain', 'Heavy Rain'])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, bike sharing utilization is getting worse with bad weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Actual Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Actual Temperature - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.actual_temp,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Actual Temperature - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.actual_temp,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization is almost inexistant for sub-zero temperatures. It then grows with the increase of temperature, but drops down when it gets extremely hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Feeling Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Feeling Temperature - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.feeling_temp,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Feeling Temperature - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.feeling_temp,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization by feeling temperature follows the same rules than by actual temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Humidity - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.humidity,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Humidity - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.humidity,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization of bike sharing services is decreasing with the increase of humidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Wind Speed - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(x = hours_df.windspeed,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Wind Speed - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(x = hours_df.windspeed,\n",
    "#              y = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stronger wind seems to discourage users to use the bike sharing service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Casual - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(y = hours_df.casual,\n",
    "#              x = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# sns.lineplot(y = hours_df.total_bikes,\n",
    "#              x = hours_df.total_bikes,\n",
    "#              color = 'orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Casual - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(y = hours_df.casual,\n",
    "#             x = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# sns.lineplot(y = hours_df.total_bikes,\n",
    "#              x = hours_df.total_bikes,\n",
    "#              color = 'orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__COMMENTS TO UPDATE__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total_bikes by Registered - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(y = hours_df.registered,\n",
    "#              x = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# sns.lineplot(y = hours_df.total_bikes,\n",
    "#              x = hours_df.total_bikes,\n",
    "#              color = 'orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Total_bikes by Registered - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(y = hours_df.registered,\n",
    "#             x = hours_df.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# sns.lineplot(y = hours_df.total_bikes,\n",
    "#              x = hours_df.total_bikes,\n",
    "#              color = 'orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__COMMENTS TO UPDATE__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casual vs Registered Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas_reg = pd.DataFrame(hours_df.registered)\n",
    "# cas_reg['casual'] = hours_df.casual\n",
    "# cas_reg['total_bikes'] = hours_df.total_bikes\n",
    "# cas_reg['ratio_cas_tot'] = np.where(cas_reg.total_bikes == 0,0,round(cas_reg.casual / cas_reg.total_bikes,4))\n",
    "# cas_reg['diff_cas_reg'] = cas_reg.registered - cas_reg.casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Ratio of Casual Users - Line Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(y = cas_reg.ratio_cas_tot,\n",
    "#              x = cas_reg.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.axhline(1, color='orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Ratio of Casual Users - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(y = cas_reg.ratio_cas_tot,\n",
    "#             x = cas_reg.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.axhline(1, color='orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ratio of Casual Users - Distribution\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.distplot(cas_reg.ratio_cas_tot,\n",
    "#              bins = 100,\n",
    "#              color = 'steelblue').axes.set(xlim = (min(cas_reg.ratio_cas_tot),max(cas_reg.ratio_cas_tot)))\n",
    "# plt.axvline(0.5, color='orange', linestyle='--')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Difference of Casual Users - Line Plot\n",
    "# x_plot = np.linspace(0, 1000, 1000)\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.lineplot(y = cas_reg.diff_cas_reg,\n",
    "#              x = cas_reg.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.plot(x_plot, x_plot, lw=1, linestyle = 'solid', color='orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Difference of Casual Users - Box Plot\n",
    "# plt.figure(figsize=(15,5))\n",
    "# sns.boxplot(y = cas_reg.diff_cas_reg,\n",
    "#             x = cas_reg.total_bikes,\n",
    "#              color = 'steelblue')\n",
    "# plt.plot(x_plot, x_plot, lw=1, linestyle = 'solid', color='orange')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__COMMENTS TO UPDATE__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Total_Bikes by Hour with Weekday Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color='red'>__TO DO__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Weekday Hue for Casual Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__TO DO__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Weather Conditions Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__TO DO__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Seasons Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__TO DO__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot = sns.PairGrid(hours_df, palette=('steelblue', 'crimson'))\n",
    "# plot = plot.map_diag(plt.hist)\n",
    "# plot = plot.map_offdiag(plt.scatter)\n",
    "# plot.add_legend()\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hours_df_num = hours_df.select_dtypes(include = ['float64', 'int64']);\n",
    "# hours_df_num.hist(figsize=(10, 14), bins=50, xlabelsize=3, ylabelsize=3, color='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(0, len(hours_df_num.columns), 5):\n",
    "#     sns.pairplot(data=hours_df_num,\n",
    "#                 x_vars=hours_df_num.columns[i:i+5],\n",
    "#                 y_vars=['total_bikes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__TO IMPROVE__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A correlation analysis will allow to identify relationships between the dataset variables. A plot of their distributions highlighting the value of the target variable might also reveal some patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# corr_1 = hours_df_num.drop('total_bikes', axis=1).corr() # We already examined SalePrice correlations\n",
    "# plt.figure(figsize=(12, 10))\n",
    "\n",
    "# sns.heatmap(corr_1[(corr_1 >= 0.5) | (corr_1 <= -0.4)], \n",
    "#             cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "#             annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hours_num_corr = hours_df_num.corr()['total_bikes'][:-1] # -1 because the latest row is SalePrice\n",
    "# golden_features_list_1 = hours_num_corr[abs(hours_num_corr) > 0.5].sort_values(ascending=False)\n",
    "# print(\"There is {} strongly correlated values with Total Bikes:\\n{}\".format(len(golden_features_list_1), golden_features_list_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color='red'>__TO IMPROVE__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scaling and Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hours_prep_scaled = hours_df.copy().drop('date',axis=1)\n",
    "df_desc(hours_prep_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(hours_prep_scaled[['actual_temp','feeling_temp','humidity','windspeed','casual','total_bikes']]))\n",
    "hours_prep_scaled[['actual_temp','feeling_temp','humidity','windspeed','casual','total_bikes']] = pd.DataFrame(scaler.fit_transform(hours_prep_scaled[['actual_temp','feeling_temp','humidity','windspeed','casual','total_bikes']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "days_prep_scaled = days_df.copy().drop('date',axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(days_prep_scaled[['actual_temp','feeling_temp','humidity','windspeed','casual','total_bikes']]))\n",
    "days_prep_scaled[['actual_temp','feeling_temp','humidity','windspeed','casual','total_bikes']] = pd.DataFrame(scaler.fit_transform(days_prep_scaled[['actual_temp','feeling_temp','humidity','windspeed','casual','total_bikes']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hours_prep_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "days_prep_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_skewness(df):\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    numeric_features = []\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype in numeric_dtypes: \n",
    "            numeric_features.append(i)\n",
    "\n",
    "    feature_skew = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':feature_skew})\n",
    "    return feature_skew, numeric_features\n",
    "\n",
    "def fix_skewness(df):\n",
    "    feature_skew, numeric_features = feature_skewness(df)\n",
    "    high_skew = feature_skew[feature_skew > 0.5]\n",
    "    skew_index = high_skew.index\n",
    "    \n",
    "    for i in skew_index:\n",
    "        df[i] = boxcox1p(df[i], boxcox_normmax(df[i]+1))\n",
    "\n",
    "    skew_features = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':skew_features})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color='red'>__HISTOGRAM BEFORE SKEWNESS__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.distplot(hours_df['humidity'], color='g', bins=100, hist_kws={'alpha': 0.4}) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fix_skewness(hours_prep_scaled)\n",
    "fix_skewness(days_prep_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_prep_scaled_encoded = hours_prep_scaled.copy()\n",
    "days_prep_scaled_encoded = days_prep_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_prep_scaled_encoded = hours_prep_scaled_encoded.drop(['registered'], axis=1)\n",
    "days_prep_scaled_encoded = days_prep_scaled_encoded.drop(['registered'], axis=1)\n",
    "df_desc(days_prep_scaled_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(df):\n",
    "    columns = df.columns\n",
    "    return df.select_dtypes(include=[np.datetime64]).columns\n",
    "\n",
    "def numerical_features(df):\n",
    "    columns = df.columns\n",
    "    return df._get_numeric_data().columns\n",
    "\n",
    "def categorical_features(df):\n",
    "    numerical_columns = numerical_features(df)\n",
    "    date_columns = date_features(df)\n",
    "    return(list(set(df.columns) - set(numerical_columns) - set(date_columns) ))\n",
    "\n",
    "def onehot_encode(df):\n",
    "    numericals = df.get(numerical_features(df))\n",
    "    new_df = numericals.copy()\n",
    "    for categorical_column in categorical_features(df):\n",
    "        new_df = pd.concat([new_df, \n",
    "                            pd.get_dummies(df[categorical_column], \n",
    "                                           prefix=categorical_column)], \n",
    "                           axis=1)\n",
    "    return new_df\n",
    "\n",
    "def onehot_encode_single(df, col_to_encode, drop = True):\n",
    "    if type(col_to_encode) != str:\n",
    "        raise TypeError ('col_to_encode should be a string.')\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    if drop == True:\n",
    "        new_df = new_df.drop([col_to_encode], axis=1)\n",
    "\n",
    "    new_df = pd.concat([new_df, \n",
    "                        pd.get_dummies(df[col_to_encode],\n",
    "                                       prefix=col_to_encode)],\n",
    "                       axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_clean = onehot_encode(hours_prep_scaled_encoded)\n",
    "days_clean = onehot_encode(days_prep_scaled_encoded)\n",
    "df_desc(hours_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "hours_clean.rename(columns={'year_0':'year_2011',\n",
    "                        'year_1':'year_2012',\n",
    "                        'holiday_0':'holiday_no',\n",
    "                        'holiday_1':'holiday_yes',\n",
    "                        'season_1':'season_spring',\n",
    "                        'season_2':'season_summer',\n",
    "                        'season_3':'season_fall',\n",
    "                        'season_4':'season_winter',\n",
    "                        'workingday_0':'workingday_no',\n",
    "                        'workingday_1':'workingday_yes',\n",
    "                        'month_1':'month_jan',\n",
    "                        'month_2':'month_feb',\n",
    "                        'month_3':'month_mar',\n",
    "                        'month_4':'month_apr',\n",
    "                        'month_5':'month_may',\n",
    "                        'month_6':'month_jun',\n",
    "                        'month_7':'month_jul',\n",
    "                        'month_8':'month_aug',\n",
    "                        'month_9':'month_sep',\n",
    "                        'month_10':'month_oct',\n",
    "                        'month_11':'month_nov',\n",
    "                        'month_12':'month_dec',\n",
    "                        'weather_condition_1':'weather_condition_clear',\n",
    "                        'weather_condition_2':'weather_condition_mist',\n",
    "                        'weather_condition_3':'weather_condition_light_rain',\n",
    "                        'weather_condition_4':'weather_condition_heavy_rain',\n",
    "                        'weekday_0':'weekday_sunday',\n",
    "                        'weekday_1':'weekday_monday',\n",
    "                        'weekday_2':'weekday_tuesday',\n",
    "                        'weekday_3':'weekday_wednesday',\n",
    "                        'weekday_4':'weekday_thursday',\n",
    "                        'weekday_5':'weekday_friday',\n",
    "                        'weekday_6':'weekday_saturday'},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_features(df, target):\n",
    "    features = list(df)\n",
    "    features.remove(target)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'total_bikes'\n",
    "features = list_features(hours_clean, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hours_clean[features]\n",
    "X_train = X.loc[(X['year_2011']==1) | ((X['year_2012']==1) & (X['month_sep']==0) & (X['month_oct']==0) & (X['month_nov']==0) & (X['month_dec']==0)),features]\n",
    "X_test = X.loc[(X['year_2012']==1) & ((X['month_sep']==1) | (X['month_oct']==1) | (X['month_nov']==1) | (X['month_dec']==1)),features]\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('X_train:', X_train.shape[0],'rows |', X_train.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('X_test:', X_test.shape[0],'rows |', X_test.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.groupby(['year_2011','year_2012','month_jan','month_feb','month_mar','month_apr','month_may','month_jun','month_jul','month_aug','month_sep','month_oct','month_nov','month_dec']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.groupby(['year_2011','year_2012','month_jan','month_feb','month_mar','month_apr','month_may','month_jun','month_jul','month_aug','month_sep','month_oct','month_nov','month_dec']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hours_clean.copy()\n",
    "y_train = y.loc[(y['year_2011']==1) | ((y['year_2012']==1) & (y['month_sep']==0) & (y['month_oct']==0) & (y['month_nov']==0) & (y['month_dec']==0)),:]\n",
    "y_test = y.loc[(y['year_2012']==1) & ((y['month_sep']==1) | (y['month_oct']==1) | (y['month_nov']==1) | (y['month_dec']==1)),:]\n",
    "y_train = pd.DataFrame(y_train[target])\n",
    "y_test = pd.DataFrame(y_test[target])\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('y_train:', y_train.shape[0],'rows |', y_train.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('y_test:', y_test.shape[0],'rows |', y_test.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<35} {!r:>}'.format('Same indexes for X_train and y_train:', X_train.index.values.tolist() == y_train.index.values.tolist()))\n",
    "print('{:<35} {!r:>}'.format('Same indexes for X_test and y_test:', X_test.index.values.tolist() == y_test.index.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features:',X.shape[0], 'items | ', X.shape[1],'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Train:',X_train.shape[0], 'items | ', X_train.shape[1],'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Test:',X_test.shape[0], 'items | ',  X_test.shape[1],'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target:',y.shape[0], 'items | ', 1,'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Train:',y_train.shape[0], 'items | ', 1,'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Test:',y_test.shape[0], 'items | ', 1,'columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Train Set is arbitrarily defined as all records until August 31st 2012, and the Test Set all records from September 1st 2012. Below function will be used to repeat the operation on future dataframes including new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, target, features):\n",
    "    X = df[features]\n",
    "    y = pd.DataFrame(df[target])\n",
    "    X_train = X.loc[(X['year_2011']==1) | ((X['year_2012']==1) & (X['month_sep']==0) & (X['month_oct']==0) & (X['month_nov']==0) & (X['month_dec']==0)),features]\n",
    "    X_test = X.loc[(X['year_2012']==1) & ((X['month_sep']==1) | (X['month_oct']==1) | (X['month_nov']==1) | (X['month_dec']==1)),features]\n",
    "    y_train = y.iloc[X_train.index.values.tolist()]\n",
    "    y_test = y.iloc[X_test.index.values.tolist()]\n",
    "    \n",
    "    print('{:<40} {!r:>}'.format('Same indexes for X and y:', X.index.values.tolist() == y.index.values.tolist()))\n",
    "    print('{:<40} {!r:>}'.format('Same indexes for X_train and y_train:', X_train.index.values.tolist() == y_train.index.values.tolist()))\n",
    "    print('{:<40} {!r:>}'.format('Same indexes for X_test and y_test:', X_test.index.values.tolist() == y_test.index.values.tolist()))\n",
    "    print()\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features:',X.shape[0], 'items | ', X.shape[1],'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Train:',X_train.shape[0], 'items | ', X_train.shape[1],'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Test:',X_test.shape[0], 'items | ',  X_test.shape[1],'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target:',y.shape[0], 'items | ', 1,'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Train:',y_train.shape[0], 'items | ', 1,'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Test:',y_test.shape[0], 'items | ', 1,'columns'))\n",
    "    print()\n",
    "    \n",
    "    return X, X_train, X_test, y, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "print('Intercept:', lm.intercept_)\n",
    "print('Coefficients:', lm.coef_)\n",
    "print('Mean squared error (MSE): {:.2f}'.format(mean_squared_error(y_test, y_pred)))\n",
    "print('Variance score (R2): {:.2f}'.format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__ADD COMMENTS__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def performLinearRegression(X_train, y_train, X_test, y_test, algorithm):\n",
    "#     lm = linear_model.LinearRegression()\n",
    "#     lm.fit(X_train, y_train)\n",
    "#     y_pred = lm.predict(X_test)\n",
    "#     return(r2_score(y_test, y_pred))\n",
    "\n",
    "# def performTimeSeriesCV(X_train, y_train, number_folds, algorithm, parameters):\n",
    "#     \"\"\"\n",
    "#     Given X_train and y_train (the test set is excluded from the Cross Validation),\n",
    "#     number of folds, the ML algorithm to implement and the parameters to test,\n",
    "#     the function acts based on the following logic: it splits X_train and y_train in a\n",
    "#     number of folds equal to number_folds. Then train on one fold and tests accuracy\n",
    "#     on the consecutive as follows:\n",
    "#     - Train on fold 1, test on 2\n",
    "#     - Train on fold 1-2, test on 3\n",
    "#     - Train on fold 1-2-3, test on 4\n",
    "#     ....\n",
    "#     Returns mean of test accuracies.\n",
    "#     \"\"\"\n",
    " \n",
    "#     print ('Parameters --------------------------------> ', parameters)\n",
    "#     print ('Size train set: ', X_train.shape)\n",
    "    \n",
    "#     # k is the size of each fold. It is computed dividing the number of \n",
    "#     # rows in X_train by number_folds. This number is floored and coerced to int\n",
    "#     k = int(np.floor(float(X_train.shape[0]) / number_folds))\n",
    "#     print ('Size of each fold: ', k)\n",
    "    \n",
    "#     # initialize to zero the accuracies array. It is important to stress that\n",
    "#     # in the CV of Time Series if I have n folds I test n-1 folds as the first\n",
    "#     # one is always needed to train\n",
    "#     r2_metric = np.zeros(number_folds-1)\n",
    " \n",
    "#     # loop from the first 2 folds to the total number of folds    \n",
    "#     for i in range(2, number_folds + 1):\n",
    "#         print ('')\n",
    "        \n",
    "#         # the split is the percentage at which to split the folds into train\n",
    "#         # and test. For example when i = 2 we are taking the first 2 folds out \n",
    "#         # of the total available. In this specific case we have to split the\n",
    "#         # two of them in half (train on the first, test on the second), \n",
    "#         # so split = 1/2 = 0.5 = 50%. When i = 3 we are taking the first 3 folds \n",
    "#         # out of the total available, meaning that we have to split the three of them\n",
    "#         # in two at split = 2/3 = 0.66 = 66% (train on the first 2 and test on the\n",
    "#         # following)\n",
    "#         split = float(i-1)/i\n",
    "        \n",
    "#         # example with i = 4 (first 4 folds):\n",
    "#         #      Splitting the first       4        chunks at          3      /        4\n",
    "#         print ('Splitting the first ' + str(i) + ' chunks at ' + str(i-1) + '/' + str(i) )\n",
    "        \n",
    "#         # as we loop over the folds X and y are updated and increase in size.\n",
    "#         # This is the data that is going to be split and it increases in size \n",
    "#         # in the loop as we account for more folds. If k = 300, with i starting from 2\n",
    "#         # the result is the following in the loop\n",
    "#         # i = 2\n",
    "#         # X = X_train[:(600)]\n",
    "#         # y = y_train[:(600)]\n",
    "#         #\n",
    "#         # i = 3\n",
    "#         # X = X_train[:(900)]\n",
    "#         # y = y_train[:(900)]\n",
    "#         # .... \n",
    "#         X = X_train[:(k*i)]\n",
    "#         y = y_train[:(k*i)]\n",
    "#         print ('Size of train + test: ', X.shape) # the size of the dataframe is going to be k*i\n",
    " \n",
    "#         # X and y contain both the folds to train and the fold to test.\n",
    "#         # index is the integer telling us where to split, according to the\n",
    "#         # split percentage we have set above\n",
    "#         index = int(np.floor(X.shape[0] * split))\n",
    "        \n",
    "#         # folds used to train the model        \n",
    "#         X_trainFolds = X[:index]        \n",
    "#         y_trainFolds = y[:index]\n",
    "        \n",
    "#         # fold used to test the model\n",
    "#         X_testFold = X[(index + 1):]\n",
    "#         y_testFold = y[(index + 1):]\n",
    "        \n",
    "#         # i starts from 2 so the zeroth element in accuracies array is i-2. performClassification() is a function which takes care of a classification problem. This is only an example and you can replace this function with whatever ML approach you need.\n",
    "#         r2_metric[i-2] = performLinearRegression(X_trainFolds, y_trainFolds, X_testFold, y_testFold, algorithm)\n",
    "        \n",
    "#         # example with i = 4:\n",
    "#         #      Accuracy on fold         4     :    0.85423\n",
    "#         print ('R2 on fold ' + str(i) + ': ', r2_metric[i-2])\n",
    "    \n",
    "#     # the function returns the mean of the accuracy on the n-1 folds    \n",
    "    \n",
    "#     r2_metric = r2_metric[r2_metric > 0]\n",
    "#     return r2_metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performTimeSeriesCV(X_train, y_train, 20, 'lm', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def cross_val_ts(X_train, y_train, n_splits):\n",
    "#     tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "#     print(tscv)  \n",
    "\n",
    "#     for train_index, test_index in tscv.split(X_train):\n",
    "#         X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "#         y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "#         lm = linear_model.LinearRegression()\n",
    "#         lm.fit(X_train_cv, y_train_cv)\n",
    "#         y_pred_cv = lm.predict(X_test_cv)\n",
    "#         print('Variance score (R2): {:.2f}'.format(r2_score(y_test_cv, y_pred_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_ts(algorithm,X_train, y_train, n_splits):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    scores = cross_validate(algorithm, X_train, y_train, cv=tscv,\n",
    "                            scoring=('r2'),\n",
    "                            return_train_score=True)\n",
    "    print('Cross Validation Variance score (R2): {:.2f}'.format(scores['train_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_ts(lm,X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day and Month-Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add the day from 'date'\n",
    "hours_FE1 = pd.concat([hours_clean,pd.DataFrame(pd.DatetimeIndex(hours_df['date']).day)], axis=1, sort=False, ignore_index=False)\n",
    "hours_FE1.rename(columns={'date':'day'}, inplace=True)\n",
    "\n",
    "# Add month-day from 'date'\n",
    "hours_FE1 = pd.concat([hours_FE1,pd.DataFrame(pd.DatetimeIndex(hours_df['date']).strftime('%m-%d'))], axis=1, sort=False, ignore_index=False)\n",
    "hours_FE1.rename(columns={0:'month_day'}, inplace=True)\n",
    "\n",
    "df_desc(hours_FE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE1 = onehot_encode_single(hours_FE1, 'day')\n",
    "hours_FE1 = onehot_encode_single(hours_FE1, 'month_day')\n",
    "df_desc(hours_FE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables `day` and `month_day` have been added to understand if patterns exist based on specific dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__TEST THE NEW FEATURE WITH CV AND MODEL__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df, target, algorithm, n_splits = 10):\n",
    "    features = list_features(df, target)\n",
    "    X, X_train, X_test, y, y_train, y_test = train_test_split(df, target, features)\n",
    "    cross_val_ts(algorithm,X_train, y_train, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(hours_FE1, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### FUNCTION TO USE: Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# performTimeSeriesCV(X_train, y_train, 20, 'lm', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color='red'>__TO UPDATE__</font>  \n",
    "The dataset resulting from the Feature Engineering phase contains 58 features, with a model reaching the accuracy of 0.964. The Feature Selection phase aims to reduce the number of variables used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TEST MODEL ON ALL FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Recursive Feature Elimination (RFE) method is used to select the most relevant features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.exceptions import ConvergenceWarning\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "# features_rfe = list(hours_clean)\n",
    "# features_rfe.remove(target)\n",
    "\n",
    "# X_rfe = hours_clean.loc[:, features_rfe]\n",
    "# y_rfe = hours_clean.loc[:, target]\n",
    "\n",
    "# linreg = LinearRegression()\n",
    "# rfe = RFE(linreg)\n",
    "# rfe = rfe.fit(X_rfe, y_rfe)\n",
    "\n",
    "# print(sum(rfe.support_),'selected features:')\n",
    "# for i in list(X_rfe.loc[:, rfe.support_]):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hours_clean_outliers  = hours_clean.copy()\n",
    "# def remove_outliers(df):\n",
    "#     x = df.drop(['total_bikes'], axis=1)\n",
    "#     y = df.total_bikes.reset_index(drop=True)\n",
    "#     ols = sm.OLS(endog = y.astype(float), exog = x.astype(float))\n",
    "#     fit = ols.fit()\n",
    "#     test = fit.outlier_test()['bonf(p)']\n",
    "#     outliers = list(test[test<1e-3].index) \n",
    "#     df.drop(df.index[outliers])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove_outliers(hours_clean_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hours_clean.equals(hours_clean_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "*Vratul Kapur | Irune Maury Arrue | Paul Jacques-Mignault | Sheena Miles | Ashley OMahony | Stavros Tsentemeidis | Karl Westphal  \n",
    "O17 (Group G) | Master in Big Data and Business Analytics | Oct 2018 Intake | IE School of Human Sciences and Technology*\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
